{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import allel\n",
    "import numpy as np \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/anushasubramanian\n"
     ]
    }
   ],
   "source": [
    "cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/anushasubramanian/Desktop/Research/UCLA/tsv\n"
     ]
    }
   ],
   "source": [
    "cd Desktop/Research/UCLA/tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7704"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = pd.read_csv('/Users/anushasubramanian/Desktop/Research/UCLA/yeast_parent_vcf/sgs1_as_csv.csv')\n",
    "sgs1 = pd.DataFrame(f)\n",
    "keys = [\"chrI\",\"chrII\",\"chrIII\",\"chrIV\",\"chrV\",\"chrVI\",\"chrVII\",\"chrVIII\",\"chrIX\",\"chrX\",\n",
    "        \"chrXI\",\"chrXII\",\"chrXIII\",\"chrXIV\", \"chrXV\",\"chrXVI\",\"chrM\"]\n",
    "sgs1PosDict = dict.fromkeys(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in sgs1PosDict:\n",
    "            sgs1PosDict[k] = list(sgs1.loc[sgs1[\"CHROM\"] == k][\"POS\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1525226"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgs1PosDict[\"chrIV\"][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "chrIVPos = dict.fromkeys(list(sgs1PosDict[\"chrIV\"]), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "chrIVCoverage = dict.fromkeys(list(sgs1PosDict[\"chrIV\"]), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Function to generate a full dataset from each file \n",
    "\n",
    "def full_data(file):\n",
    "    \n",
    "    \"\"\" To generate the full data associated with a vcf file passed in \"\"\"\n",
    "    \n",
    "    data = pd.read_csv( file, sep = '\\t')\n",
    "    chrIV = data.loc[data[\"#CHROM\"] == \"chrIV\"] # all chrIV only\n",
    "    chrIV.columns = ['CHROM', 'POS', 'ID', 'REF', 'ALT', 'QUAL', 'FILTER', 'INFO', 'FORMAT','psl5',\n",
    "                   'psl2','yi283']\n",
    "\n",
    "\n",
    "    # only use positions from sgs1\n",
    "    for pos in chrIV[\"POS\"]:\n",
    "        if pos not in sgs1PosDict[\"chrIV\"]:\n",
    "            chrIV.drop(chrIV.loc[chrIV[\"POS\"] == pos].index, inplace = True)\n",
    "\n",
    "    #3. Cleaning the yi283 data to be in usable form, with ref and alt reads separated\n",
    "    ref = []\n",
    "    alt = []\n",
    "    all_ref = []\n",
    "    all_alt = []\n",
    "\n",
    "    error = []\n",
    "    for item in chrIV[\"yi283\"]:\n",
    "        reads = item.split(sep = ':')[1:3]\n",
    "        if len(reads) == 2:\n",
    "            for read in reads: \n",
    "                tokens = read.split(sep = ',')\n",
    "                ref.append(tokens[0])\n",
    "                alt.append(tokens[1])\n",
    "            all_ref.append([int(x) for x in ref])\n",
    "            all_alt.append([int(x) for x in alt])\n",
    "            ref = []\n",
    "            alt = []   \n",
    "        else:\n",
    "            error.append(item)\n",
    "            \n",
    "    # Finding sum of the reference and alternative reads \n",
    "    sum_ref = []\n",
    "    sum_alt = []\n",
    "\n",
    "    for ref in all_ref:\n",
    "        sum_ref.append(sum(ref))\n",
    "    for alt in all_alt:\n",
    "        sum_alt.append(sum(alt))\n",
    "\n",
    "\n",
    "    # finding the total number of reads by summing all ref and alts\n",
    "    zipped = zip(sum_ref, sum_alt)\n",
    "    tot_reads = [x+y for (x,y) in zipped]\n",
    "\n",
    "    cleaned_chrIV = pd.DataFrame()\n",
    "    cleaned_chrIV[\"CHROM\"] = chrIV[\"CHROM\"]\n",
    "    cleaned_chrIV[\"POS\"] = chrIV[\"POS\"]\n",
    "    cleaned_chrIV[\"total reads\"] = tot_reads\n",
    "    cleaned_chrIV[\"ref reads\"] = all_ref\n",
    "    cleaned_chrIV[\"alt reads\"] = all_alt\n",
    "    cleaned_chrIV[\"sum_ref\"] = sum_ref\n",
    "    cleaned_chrIV[\"sum_alt\"] = sum_alt\n",
    "    \n",
    "\n",
    "    # percentage of ref = sum ref / total reads\n",
    "    refPer = []\n",
    "    altPer = []\n",
    "\n",
    "    for ref, reads in zip(sum_ref, tot_reads):\n",
    "        refPer.append((ref/reads)*100)\n",
    "    for alt, reads in zip(sum_alt, tot_reads):\n",
    "        altPer.append((alt/reads)*100)\n",
    "\n",
    "    cleaned_chrIV[\"%ref\"] = refPer\n",
    "    cleaned_chrIV[\"%alt\"] = altPer\n",
    "\n",
    "    # quick check to make sure that all the entries are either 0 or 100\n",
    "    e = False\n",
    "    for alt in altPer:\n",
    "        if alt!=0 and alt!=100:\n",
    "            e = True\n",
    "            \n",
    "    #reset the index so we can access multiple columns of df\n",
    "    cleaned_chrIV.reset_index(drop = True, inplace=True)\n",
    "    \n",
    "    # Classify each position as alt or ref\n",
    "    classify = []\n",
    "    for ind in cleaned_chrIV.index:\n",
    "        if cleaned_chrIV[\"%ref\"][ind] > cleaned_chrIV[\"%alt\"][ind]:\n",
    "            classify.append(\"ref\")\n",
    "        elif cleaned_chrIV[\"%alt\"][ind] > cleaned_chrIV[\"%ref\"][ind]:\n",
    "            classify.append(\"alt\")\n",
    "        else:\n",
    "            classify.append('ref/alt')\n",
    "            \n",
    "    cleaned_chrIV[\"pos classification\"] = classify\n",
    "    \n",
    "    chrIV.drop(columns=[\"ID\",\"REF\",\"ALT\",\"QUAL\",\"FILTER\"], inplace=True)\n",
    "    \n",
    "    \n",
    "    # Get whether positions are alt or ref for PSL5\n",
    "    \n",
    "    ref5 = []\n",
    "    alt5 = []\n",
    "    all_ref5 = []\n",
    "    all_alt5 = []\n",
    "\n",
    "    error = []\n",
    "    for item in chrIV[\"psl5\"]:\n",
    "        reads = item.split(sep = ':')[1:3]\n",
    "        if len(reads) == 2:\n",
    "            for read in reads:\n",
    "                tokens = read.split(sep = ',')\n",
    "                ref5.append(tokens[0])\n",
    "                alt5.append(tokens[1])\n",
    "            all_ref5.append([int(x) for x in ref5])\n",
    "            all_alt5.append([int(x) for x in alt5])\n",
    "            ref5 = []\n",
    "            alt5 = []   \n",
    "        else:\n",
    "            error.append(item)\n",
    "            \n",
    "    #Finding sum of the reference and alternative reads in psl5\n",
    "    sum_ref5 = []\n",
    "    sum_alt5 = []\n",
    "\n",
    "    for ref in all_ref5:\n",
    "        sum_ref5.append(sum(ref))\n",
    "    for alt in all_alt5:\n",
    "        sum_alt5.append(sum(alt))\n",
    "\n",
    "    # finding the total number of reads by summing all ref and alts\n",
    "    zipped = zip(sum_ref5, sum_alt5)\n",
    "    tot_reads5 = [x+y for (x,y) in zipped]\n",
    "    \n",
    "    \n",
    "    \n",
    "    # percentage of ref = sum ref / total reads\n",
    "\n",
    "    refPer5 = []\n",
    "    altPer5 = []\n",
    "\n",
    "    for ref, reads in zip(sum_ref5, tot_reads5):\n",
    "        refPer5.append((ref/reads)*100)\n",
    "    for alt, reads in zip(sum_alt5, tot_reads5):\n",
    "        altPer5.append((alt/reads)*100)\n",
    "\n",
    "\n",
    "\n",
    "    classify5 = []\n",
    "    for alt,ref in zip(altPer5, refPer5):\n",
    "        if ref > alt:\n",
    "            classify5.append(\"ref\")\n",
    "        elif alt > ref:\n",
    "            classify5.append(\"alt\")\n",
    "        else:\n",
    "            classify5.append('ref/alt')\n",
    "    \n",
    "    \n",
    "    cleaned_chrIV[\"psl5 pos\"] = classify5\n",
    "    \n",
    "    # Get whether positions are alt or ref for PSL2\n",
    "    ref2 = []\n",
    "    alt2 = []\n",
    "    all_ref2 = []\n",
    "    all_alt2 = []\n",
    "\n",
    "    error = []\n",
    "    for item in chrIV[\"psl2\"]:\n",
    "        reads = item.split(sep = ':')[1:3]\n",
    "        if len(reads) == 2:\n",
    "            for read in reads:\n",
    "                tokens = read.split(sep = ',')\n",
    "                ref2.append(tokens[0])\n",
    "                alt2.append(tokens[1])\n",
    "            all_ref2.append([int(x) for x in ref2])\n",
    "            all_alt2.append([int(x) for x in alt2])\n",
    "            ref2 = []\n",
    "            alt2 = []   \n",
    "        else:\n",
    "            error.append(item)\n",
    "\n",
    "\n",
    "    #Finding sum of the reference and alternative reads in psl5\n",
    "    sum_ref2 = []\n",
    "    sum_alt2 = []\n",
    "\n",
    "    for ref in all_ref2:\n",
    "        sum_ref2.append(sum(ref))\n",
    "    for alt in all_alt2:\n",
    "        sum_alt2.append(sum(alt))\n",
    "\n",
    "\n",
    "    # finding the total number of reads by summing all ref and alts\n",
    "    zipped = zip(sum_ref2, sum_alt2)\n",
    "    tot_reads2 = [x+y for (x,y) in zipped]\n",
    "\n",
    "\n",
    "    # percentage of ref = sum ref / total reads\n",
    "\n",
    "    refPer2 = []\n",
    "    altPer2 = []\n",
    "\n",
    "    for ref, reads in zip(sum_ref2, tot_reads2):\n",
    "        if reads!= 0:\n",
    "            refPer2.append((ref/reads)*100)\n",
    "        else:\n",
    "            refPer2.append(999)\n",
    "\n",
    "    for alt, reads in zip(sum_alt2, tot_reads2):\n",
    "        if reads!= 0:\n",
    "            altPer2.append((alt/reads)*100)\n",
    "        else:\n",
    "            altPer2.append(999)\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    classify2 = []\n",
    "    for alt,ref in zip(altPer2, refPer2):\n",
    "        if ref > alt:\n",
    "            classify2.append(\"ref\")\n",
    "        elif alt > ref:\n",
    "            classify2.append(\"alt\")\n",
    "        elif alt == 999 and ref == 999:\n",
    "            classify2.append('no reads')\n",
    "        else:\n",
    "            classify2.append('ref/alt')\n",
    "\n",
    "\n",
    "    cleaned_chrIV[\"psl2 pos\"] = classify2\n",
    "    \n",
    "    # So what strain is the yi283 position from?\n",
    "    \n",
    "    strain = []\n",
    "    for ind in cleaned_chrIV.index:\n",
    "        if cleaned_chrIV[\"pos classification\"][ind] == 'ref/alt':\n",
    "            strain.append('psl5/psl2')\n",
    "        else:\n",
    "            if cleaned_chrIV[\"pos classification\"][ind] == cleaned_chrIV[\"psl5 pos\"][ind]:\n",
    "                strain.append(\"psl5\")\n",
    "\n",
    "            elif cleaned_chrIV[\"pos classification\"][ind] == cleaned_chrIV[\"psl2 pos\"][ind]:\n",
    "                strain.append(\"psl2\")\n",
    "            else:\n",
    "                strain.append(\"inconclusive\")\n",
    "                \n",
    "    cleaned_chrIV[\"strain\"] = strain\n",
    "    \n",
    "    psl5Per = []\n",
    "    psl2Per = []\n",
    "\n",
    "    for ind in cleaned_chrIV.index:\n",
    "\n",
    "        if cleaned_chrIV[\"strain\"][ind] == 'psl5/psl2':\n",
    "            psl5Per.append(cleaned_chrIV[\"%ref\"][ind])\n",
    "            psl2Per.append(cleaned_chrIV[\"%alt\"][ind])\n",
    "\n",
    "        elif cleaned_chrIV[\"strain\"][ind] == \"psl5\":\n",
    "\n",
    "            if cleaned_chrIV[\"pos classification\"][ind] == 'alt':\n",
    "                psl5Per.append(cleaned_chrIV[\"%alt\"][ind])\n",
    "                psl2Per.append(cleaned_chrIV[\"%ref\"][ind])\n",
    "\n",
    "            elif cleaned_chrIV[\"pos classification\"][ind] == 'ref':\n",
    "                psl5Per.append(cleaned_chrIV[\"%ref\"][ind])\n",
    "                psl2Per.append(cleaned_chrIV[\"%alt\"][ind])\n",
    "\n",
    "        elif cleaned_chrIV[\"strain\"][ind] == \"psl2\":\n",
    "\n",
    "            if cleaned_chrIV[\"pos classification\"][ind] == 'alt':\n",
    "                psl2Per.append(cleaned_chrIV[\"%alt\"][ind])\n",
    "                psl5Per.append(cleaned_chrIV[\"%ref\"][ind])\n",
    "\n",
    "            elif cleaned_chrIV[\"pos classification\"][ind] == 'ref':\n",
    "                psl2Per.append(cleaned_chrIV[\"%ref\"][ind])\n",
    "                psl5Per.append(cleaned_chrIV[\"%alt\"][ind])\n",
    "\n",
    "        elif cleaned_chrIV[\"strain\"][ind] == 'inconclusive':\n",
    "            psl5Per.append(-1)\n",
    "            psl2Per.append(-1)\n",
    "            \n",
    "    cleaned_chrIV[\"psl5%\"] = psl5Per\n",
    "    cleaned_chrIV[\"psl2%\"] = psl2Per\n",
    "    \n",
    "    return cleaned_chrIV\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsv_names = [x for x in os.listdir() if x.find(\".tsv\") != -1]\n",
    "\n",
    "# single_cell_data = dict.fromkeys(tsv_names, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "for tsv in tsv_names:\n",
    "    df = full_data(tsv)\n",
    "    df.to_csv(f'/Users/anushasubramanian/Desktop/Research/UCLA/single cell aggregated data/{tsv}', \n",
    "              sep = '\\t', index = False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
